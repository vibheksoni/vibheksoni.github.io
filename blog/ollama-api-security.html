<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Exposing the Risks of Open Ollama APIs | Vibhek Soni</title>
    <link rel="stylesheet" href="../styles/main.css">
    <link rel="stylesheet" href="../styles/blog.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>
<body class="blog-post-page">
    <nav class="blog-nav">
        <div class="nav-container">
            <a href="../index.html" class="nav-brand">Vibhek Soni</a>
            <div class="nav-links">
                <a href="../index.html">Home</a>
                <a href="../blog.html" class="active">Blog</a>
            </div>
        </div>
    </nav>

    <main>
        <div class="post-container">
            <header class="post-header">
                <a href="../blog.html" class="back-link">
                    <i class="fas fa-arrow-left"></i> Back to Blog
                </a>
                <h1>Exposing the Risks of Open Ollama APIs</h1>
                <p class="post-subtitle">How the popular Ollama API service can be exposed to the internet if not secured, and practical steps to protect your machine from unauthorized access.</p>
                <div class="post-meta">
                    <time>January 23, 2025</time>
                    <span>4 min read</span>
                </div>
                <div class="post-tags">
                    <span class="post-tag">API Security</span>
                    <span class="post-tag">Ollama</span>
                    <span class="post-tag">Network Security</span>
                </div>
            </header>

            <article class="post-content">
                <h2>The Problem</h2>
                <p>Ollama is a popular API service that runs locally on your machine, letting you use AI models without relying on external cloud infrastructure. It operates on port <strong>11434</strong> and is accessible via <code>http://localhost:11434</code>.</p>
                
                <p>Here's the issue: Ollama has no built-in authentication. While this isn't a vulnerability in the traditional sense, it creates a significant risk. If your machine's port is exposed to the internet, anyone can access your Ollama service and use your resources without permission.</p>

                <h2>What Can Go Wrong</h2>
                <p>Without authentication and with an open port, an attacker could:</p>
                <ul>
                    <li>Interact with your AI models</li>
                    <li>Download models running on your machine</li>
                    <li>Execute tasks using your hardware resources</li>
                </ul>
                <p>For developers with high-performance machines or those running on cloud providers, this could lead to significant resource usage and unexpected bills.</p>

                <h2>How I Found This</h2>
                <p>While exploring the <code>ollama serve</code> command, I realized the service is already running if Ollama is installed and active. I searched for machines exposing port 11434 using Censys, an internet search engine for ports and services.</p>
                
                <p>The results were concerning:</p>
                <ul>
                    <li>Several machines with open port 11434 were publicly accessible</li>
                    <li>I could interact with exposed endpoints, download models, and use their hardware</li>
                    <li>Many instances were running on high-powered setups, likely without the owner's knowledge</li>
                </ul>

                <h2>How to Protect Your Ollama Service</h2>
                <p>If you use Ollama, take these steps to secure your service:</p>
                
                <h3>1. IP Whitelisting</h3>
                <p>Use a firewall to restrict access to trusted IPs only.</p>

                <h3>2. Add an Authentication Wrapper</h3>
                <p>Implement a wrapper or proxy service that requires authentication before interacting with the Ollama API.</p>

                <h3>3. Disable Public Port Access</h3>
                <p>Ensure port 11434 is not accessible from the internet. Configure it to allow local access only.</p>

                <h2>Conclusion</h2>
                <p>This isn't about blaming Ollamaâ€”it's about understanding the risks of running local services without proper network configuration. By implementing basic security measures, you can protect your system from unauthorized access and ensure your resources stay yours.</p>
            </article>

            <footer class="post-footer">
                <div class="author-box">
                    <img src="../pfp.webp" alt="Vibhek Soni">
                    <div class="author-info">
                        <h4>Vibhek Soni</h4>
                        <p>Security Researcher</p>
                    </div>
                </div>
            </footer>
        </div>
    </main>

    <footer class="blog-footer">
        <p>&copy; 2025 Vibhek Soni</p>
    </footer>
</body>
</html>